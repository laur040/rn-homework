{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2l9CrXbH_Jw",
        "outputId": "17d295bf-a932-4ca6-ebbf-89f728226839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 39139658.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 549759.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1441033.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4602688.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torchvision.datasets import MNIST\n",
        "def download_mnist(is_train: bool):\n",
        "    dataset = MNIST(root='./data',\n",
        "            transform=lambda x: np.array(x).flatten(),\n",
        "            download=True,\n",
        "            train=is_train)\n",
        "    mnist_data = []\n",
        "    mnist_labels = []\n",
        "    for image, label in dataset:\n",
        "        mnist_data.append(image)\n",
        "        mnist_labels.append(label)\n",
        "    return mnist_data, mnist_labels\n",
        "train_X, train_Y = download_mnist(True)\n",
        "test_X, test_Y = download_mnist(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the data and convert the labels to one-hot-encoding"
      ],
      "metadata": {
        "id": "P2UdAUVoIyIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = np.array(train_X) / 255.0\n",
        "test_X = np.array(test_X) / 255.0"
      ],
      "metadata": {
        "id": "E0b4Tj4FIOaI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(labels):\n",
        "  # labels = labels.astype(int)\n",
        "  one_hot_encode = np.zeros((len(labels), 10))\n",
        "  for i in range (len(labels)):\n",
        "    one_hot_encode[i, labels[i]] = 1\n",
        "  return one_hot_encode\n",
        "\n",
        "train_Y = one_hot_encoding(train_Y)\n",
        "test_Y = one_hot_encoding(test_Y)"
      ],
      "metadata": {
        "id": "ID-roNiJIbUi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_param(input, output):\n",
        "  W = np.random.rand(input, output) * 0.01\n",
        "  b = np.zeros((output,))\n",
        "  return W, b\n",
        "\n",
        "#print(init_param(784, 10))\n"
      ],
      "metadata": {
        "id": "DOYq2dGMJzw8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax, Cross Entrpy Loss, Gradient Descent"
      ],
      "metadata": {
        "id": "yFwD0I3ZJdBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  exp_x = np.exp(x - np.max(x, axis = 1, keepdims = True))\n",
        "  return exp_x / np.sum(exp_x, axis = 1, keepdims = True)"
      ],
      "metadata": {
        "id": "8rMHCx4RL5R2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(true_y, prediction_y):\n",
        "  m = true_y.shape[0]\n",
        "  log_p = -np.log(prediction_y[range(m), true_y.argmax(axis=1)] + 1e-9)\n",
        "  loss = np.sum(log_p) / m\n",
        "\n",
        "  return loss\n"
      ],
      "metadata": {
        "id": "JhMb3IA3P2t5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, true_y, prediction_y, W, b, learning_rate):\n",
        "  error = true_y - prediction_y\n",
        "  W += learning_rate * (np.dot(X.T, error))\n",
        "  b += learning_rate * np.sum(error, axis = 0)\n",
        "  return W, b"
      ],
      "metadata": {
        "id": "IwI5WvpUXEMl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction, Accuracy"
      ],
      "metadata": {
        "id": "8S1Pw4jRJcpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, W, b):\n",
        "  z = np.dot(X, W) + b\n",
        "  prediction_y = softmax(z)\n",
        "  #return prediction_y\n",
        "  return np.argmax(prediction_y, axis = 1)"
      ],
      "metadata": {
        "id": "2YLPxJj8O8Zc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(X, Y, W, b):\n",
        "  prediction_y = predict(X, W, b)\n",
        "  true_y = np.argmax(Y, axis = 1)\n",
        "\n",
        "  acc = np.mean(prediction_y == true_y)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "C3aScSVEcNrq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "0mX8dfOWJsy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_X, train_Y, W, b, epochs=100, batch_size=100, learning_rate=0.01):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    i = np.random.permutation(train_X.shape[0])\n",
        "    train_X_random = train_X[i]\n",
        "    train_Y_random = train_Y[i]\n",
        "\n",
        "    for i in range(0, train_X.shape[0], batch_size):\n",
        "      batch_X = train_X_random[i : i + batch_size]\n",
        "      batch_Y = train_Y_random[i : i + batch_size]\n",
        "\n",
        "      #prediction_y = predict(batch_X, W, b)\n",
        "      z = np.dot(batch_X, W) + b\n",
        "      prediction_y = softmax(z)\n",
        "\n",
        "      loss = cross_entropy(batch_Y, prediction_y)\n",
        "\n",
        "      W, b = gradient_descent(batch_X, batch_Y, prediction_y, W, b, learning_rate)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1} Loss: {loss}\")\n",
        "\n",
        "  return W, b\n"
      ],
      "metadata": {
        "id": "tRY6JQkfYRtO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W, b = init_param(784,10)\n",
        "trained_W, trained_b = train(train_X, train_Y, W, b, 100, 100, 0.01)\n",
        "\n",
        "test_acc = accuracy(test_X, test_Y, trained_W, trained_b)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}% \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKdwMhCidtyi",
        "outputId": "bc58fa3b-9ef4-48b6-db3f-17454280a4e0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss: 0.30929166590945134\n",
            "Epoch: 2 Loss: 0.4597783190294895\n",
            "Epoch: 3 Loss: 0.26618713888362816\n",
            "Epoch: 4 Loss: 0.4406843995642879\n",
            "Epoch: 5 Loss: 0.3664150648154956\n",
            "Epoch: 6 Loss: 0.30041437496228957\n",
            "Epoch: 7 Loss: 0.2566326378408545\n",
            "Epoch: 8 Loss: 0.15781139236378464\n",
            "Epoch: 9 Loss: 0.31266051480564\n",
            "Epoch: 10 Loss: 0.2583511212249546\n",
            "Epoch: 11 Loss: 0.29609675155815046\n",
            "Epoch: 12 Loss: 0.30092225017425384\n",
            "Epoch: 13 Loss: 0.20406806047831388\n",
            "Epoch: 14 Loss: 0.3120026151793684\n",
            "Epoch: 15 Loss: 0.15348898703323127\n",
            "Epoch: 16 Loss: 0.2753844101263681\n",
            "Epoch: 17 Loss: 0.3996708442133541\n",
            "Epoch: 18 Loss: 0.20697995448979878\n",
            "Epoch: 19 Loss: 0.274803574839431\n",
            "Epoch: 20 Loss: 0.2621752748185944\n",
            "Epoch: 21 Loss: 0.25518442215339965\n",
            "Epoch: 22 Loss: 0.2636244600556344\n",
            "Epoch: 23 Loss: 0.4078324404160319\n",
            "Epoch: 24 Loss: 0.40117248704114417\n",
            "Epoch: 25 Loss: 0.2052941509180527\n",
            "Epoch: 26 Loss: 0.17554440620898737\n",
            "Epoch: 27 Loss: 0.27337562538306626\n",
            "Epoch: 28 Loss: 0.23288719044506748\n",
            "Epoch: 29 Loss: 0.285893999946534\n",
            "Epoch: 30 Loss: 0.40756386270577605\n",
            "Epoch: 31 Loss: 0.4245508538290182\n",
            "Epoch: 32 Loss: 0.3424365634409719\n",
            "Epoch: 33 Loss: 0.35687322592920323\n",
            "Epoch: 34 Loss: 0.3159404283449423\n",
            "Epoch: 35 Loss: 0.2523024361530132\n",
            "Epoch: 36 Loss: 0.29543989278373844\n",
            "Epoch: 37 Loss: 0.2854938202359926\n",
            "Epoch: 38 Loss: 0.2568536615580596\n",
            "Epoch: 39 Loss: 0.3184009176287406\n",
            "Epoch: 40 Loss: 0.24272436634131708\n",
            "Epoch: 41 Loss: 0.15360404074048847\n",
            "Epoch: 42 Loss: 0.20899888914275797\n",
            "Epoch: 43 Loss: 0.3824781803794922\n",
            "Epoch: 44 Loss: 0.1732062868415629\n",
            "Epoch: 45 Loss: 0.21538677188045596\n",
            "Epoch: 46 Loss: 0.1711405693983656\n",
            "Epoch: 47 Loss: 0.16579495794492\n",
            "Epoch: 48 Loss: 0.3986192049639805\n",
            "Epoch: 49 Loss: 0.26383533695164885\n",
            "Epoch: 50 Loss: 0.48861821478322015\n",
            "Epoch: 51 Loss: 0.21445623850786302\n",
            "Epoch: 52 Loss: 0.3297256699859384\n",
            "Epoch: 53 Loss: 0.1628869199837073\n",
            "Epoch: 54 Loss: 0.13972742007809666\n",
            "Epoch: 55 Loss: 0.24769909391150144\n",
            "Epoch: 56 Loss: 0.2408763019854458\n",
            "Epoch: 57 Loss: 0.1777772439824967\n",
            "Epoch: 58 Loss: 0.31318707003055984\n",
            "Epoch: 59 Loss: 0.15593852497964136\n",
            "Epoch: 60 Loss: 0.15359703066264974\n",
            "Epoch: 61 Loss: 0.34502260693547776\n",
            "Epoch: 62 Loss: 0.17850429419580574\n",
            "Epoch: 63 Loss: 0.25359906187466946\n",
            "Epoch: 64 Loss: 0.1462054240435408\n",
            "Epoch: 65 Loss: 0.5393947435021869\n",
            "Epoch: 66 Loss: 0.383020472518641\n",
            "Epoch: 67 Loss: 0.4981137805029176\n",
            "Epoch: 68 Loss: 0.2681916758089823\n",
            "Epoch: 69 Loss: 0.17751936410458732\n",
            "Epoch: 70 Loss: 0.3193328620207067\n",
            "Epoch: 71 Loss: 0.2884293180543908\n",
            "Epoch: 72 Loss: 0.17199966011903245\n",
            "Epoch: 73 Loss: 0.19039765368761835\n",
            "Epoch: 74 Loss: 0.268999438873345\n",
            "Epoch: 75 Loss: 0.3189557035627839\n",
            "Epoch: 76 Loss: 0.3189911015519442\n",
            "Epoch: 77 Loss: 0.17289605456346002\n",
            "Epoch: 78 Loss: 0.2940380631577981\n",
            "Epoch: 79 Loss: 0.3148077120255052\n",
            "Epoch: 80 Loss: 0.23381516613427944\n",
            "Epoch: 81 Loss: 0.22255744380807183\n",
            "Epoch: 82 Loss: 0.2372466528581047\n",
            "Epoch: 83 Loss: 0.19812437732754348\n",
            "Epoch: 84 Loss: 0.416050884699875\n",
            "Epoch: 85 Loss: 0.12646136256543297\n",
            "Epoch: 86 Loss: 0.1362786749835655\n",
            "Epoch: 87 Loss: 0.38738078526525\n",
            "Epoch: 88 Loss: 0.19550515505397545\n",
            "Epoch: 89 Loss: 0.2043851853278695\n",
            "Epoch: 90 Loss: 0.1760274600693405\n",
            "Epoch: 91 Loss: 0.19647778667684762\n",
            "Epoch: 92 Loss: 0.2827407194493955\n",
            "Epoch: 93 Loss: 0.3616851070194236\n",
            "Epoch: 94 Loss: 0.28167343530147204\n",
            "Epoch: 95 Loss: 0.13103630339402839\n",
            "Epoch: 96 Loss: 0.12053961981522829\n",
            "Epoch: 97 Loss: 0.15729080268940154\n",
            "Epoch: 98 Loss: 0.10979189401424089\n",
            "Epoch: 99 Loss: 0.34435684162497443\n",
            "Epoch: 100 Loss: 0.35586173481491296\n",
            "Test accuracy: 91.95% \n"
          ]
        }
      ]
    }
  ]
}