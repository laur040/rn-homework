{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFlme-SjrKXg",
        "outputId": "b9d21e59-347d-4f1e-d749-b938372478f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 52.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.75MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.76MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from torchvision.datasets import MNIST\n",
        "def download_mnist(is_train: bool):\n",
        "    dataset = MNIST(root='./data',\n",
        "            transform=lambda x: np.array(x).flatten(),\n",
        "            download=True,\n",
        "            train=is_train)\n",
        "    mnist_data = []\n",
        "    mnist_labels = []\n",
        "    for image, label in dataset:\n",
        "        mnist_data.append(image)\n",
        "        mnist_labels.append(label)\n",
        "    return mnist_data, mnist_labels\n",
        "train_X, train_Y = download_mnist(True)\n",
        "test_X, test_Y = download_mnist(False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = np.array(train_X) / 255.0\n",
        "test_X = np.array(test_X) / 255.0"
      ],
      "metadata": {
        "id": "r7VZ1G7erNFc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(labels):\n",
        "  one_hot_encode = np.zeros((len(labels), 10))\n",
        "  for i in range (len(labels)):\n",
        "    one_hot_encode[i, labels[i]] = 1\n",
        "  return one_hot_encode\n",
        "\n",
        "train_Y = one_hot_encoding(train_Y)\n",
        "test_Y = one_hot_encoding(test_Y)"
      ],
      "metadata": {
        "id": "xsJDGxi5rPU3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_param(input, output, hidden):\n",
        "  limit_hidden = np.sqrt(6 / (input + hidden))\n",
        "  W_hidden = np.random.uniform(-limit_hidden, limit_hidden, (input, hidden))\n",
        "\n",
        "  limit_output = np.sqrt(6 / (output + hidden))\n",
        "  W_output = np.random.uniform(-limit_output, limit_output, (hidden, output))\n",
        "\n",
        "  b_hidden = np.zeros((1,hidden))\n",
        "  b_output = np.zeros((1,output))\n",
        "  return W_hidden, W_output, b_hidden, b_output"
      ],
      "metadata": {
        "id": "m_9pnZf5rTrN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def relu_deriv(x):\n",
        "  return (x > 0).astype(float)\n",
        "\n",
        "def softmax(x):\n",
        "  exp_x = np.exp(x - np.max(x, axis = 1, keepdims = True))\n",
        "  return exp_x / np.sum(exp_x, axis = 1, keepdims = True)"
      ],
      "metadata": {
        "id": "dDR4QGtvrWAp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_cost(Y,y_output, W_hidden, W_output, lambdaL1):\n",
        "  m = Y.shape[0]\n",
        "  cross_entropy = -np.sum(Y * np.log(y_output)) / m\n",
        "\n",
        "  l1 = (np.sum(np.abs(W_hidden)) + np.sum(np.abs(W_output))) * lambdaL1 / m\n",
        "  cost = cross_entropy + l1\n",
        "  return cost"
      ],
      "metadata": {
        "id": "uON--Oj9rWoQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, W_hidden, W_output, b_hidden, b_output):\n",
        "  z_hidden = np.dot(X, W_hidden) + b_hidden\n",
        "  y_hidden = relu(z_hidden)\n",
        "\n",
        "  z_output = np.dot(y_hidden, W_output) + b_output\n",
        "  y_output = softmax(z_output)\n",
        "\n",
        "  return y_output"
      ],
      "metadata": {
        "id": "mvLQchx5rY_f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagation(X, Y, W_hidden, W_output, b_hidden, b_output, learning_rate, lambdaL1):\n",
        "  #forward\n",
        "  z_hidden = np.dot(X, W_hidden) + b_hidden\n",
        "  y_hidden = relu(z_hidden)\n",
        "\n",
        "  z_output = np.dot(y_hidden, W_output) + b_output\n",
        "  y_output = softmax(z_output)\n",
        "\n",
        "  #back\n",
        "  dz_output = y_output - Y\n",
        "  dW_output = np.dot(y_hidden.T, dz_output) / X.shape[0]\n",
        "  db_output = np.sum(dz_output, axis=0, keepdims=True) / X.shape[0]\n",
        "\n",
        "  #l1\n",
        "  dW_output = dW_output + (lambdaL1 / X.shape[0] ) * np.sign(W_output)\n",
        "\n",
        "  dz_hidden = np.dot(dz_output, W_output.T) * relu_deriv(z_hidden)\n",
        "  dW_hidden = np.dot(X.T, dz_hidden) / X.shape[0]\n",
        "  db_hidden = np.sum(dz_hidden, axis=0, keepdims=True) / X.shape[0]\n",
        "\n",
        "  #l1\n",
        "  dW_hidden = dW_hidden + (lambdaL1 / X.shape[0] ) * np.sign(W_hidden)\n",
        "\n",
        "\n",
        "  W_hidden = W_hidden - learning_rate * dW_hidden\n",
        "  b_hidden = b_hidden - learning_rate * db_hidden\n",
        "  W_output = W_output - learning_rate * dW_output\n",
        "  b_output = b_output - learning_rate * db_output\n",
        "\n",
        "  return W_hidden, W_output, b_hidden, b_output\n"
      ],
      "metadata": {
        "id": "jxxq6KEgrbYc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_X, train_Y, W_hidden, W_output, b_hidden, b_output, epochs=100, batch_size=100, learning_rate=0.01, lambdaL1=0.01):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    i = np.random.permutation(train_X.shape[0])\n",
        "    train_X_random = train_X[i]\n",
        "    train_Y_random = train_Y[i]\n",
        "\n",
        "    epoch_cost = 0\n",
        "    for i in range(0, train_X.shape[0], batch_size):\n",
        "      batch_X = train_X_random[i : i + batch_size]\n",
        "      batch_Y = train_Y_random[i : i + batch_size]\n",
        "\n",
        "      y_output = forward_propagation(batch_X,W_hidden, W_output, b_hidden, b_output)\n",
        "\n",
        "      batch_cost = cross_entropy_cost(batch_Y, y_output, W_hidden, W_output, lambdaL1)\n",
        "      epoch_cost += batch_cost\n",
        "\n",
        "      W_hidden,W_output, b_hidden, b_output = backpropagation(batch_X, batch_Y, W_hidden,  W_output, b_hidden, b_output, learning_rate, lambdaL1)\n",
        "\n",
        "    epoch_cost = epoch_cost / (train_X.shape[0] / batch_size)\n",
        "    print(f\"Epoch: {epoch+1} Cost:{epoch_cost} \")\n",
        "\n",
        "  return W_hidden, W_output, b_hidden, b_output"
      ],
      "metadata": {
        "id": "7e14TZWqr9t1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(test_X, test_Y, W_hidden, W_output, b_hidden, b_output):\n",
        "  y_output = forward_propagation(test_X, W_hidden, W_output, b_hidden, b_output)\n",
        "\n",
        "  prediction = np.argmax(y_output, axis=1)\n",
        "  true_Y = np.argmax(test_Y, axis=1)\n",
        "\n",
        "  accuracy = np.mean(prediction == true_Y)\n",
        "  return accuracy * 100"
      ],
      "metadata": {
        "id": "dwDBsa92sA-5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_hidden, W_output, b_hidden, b_output = init_param(784,10,100)\n",
        "trained_W_hidden, trained_W_output, trained_b_hidden, trained_b_output = train(train_X, train_Y, W_hidden, W_output, b_hidden, b_output, 100, 100, 0.01, 0.01)\n",
        "\n",
        "test_acc = accuracy(test_X, test_Y, trained_W_hidden, trained_W_output, trained_b_hidden, trained_b_output)\n",
        "print(f\"Test accuracy: {test_acc:.2f}% \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCMZ9cW9sDzb",
        "outputId": "7bf90c4a-e30a-4371-8223-f109d021fe1b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Cost:1.4621186182559152 \n",
            "Epoch: 2 Cost:0.8481272472719671 \n",
            "Epoch: 3 Cost:0.7464820228252254 \n",
            "Epoch: 4 Cost:0.6996455573161321 \n",
            "Epoch: 5 Cost:0.6697219673419479 \n",
            "Epoch: 6 Cost:0.6473410541388831 \n",
            "Epoch: 7 Cost:0.6289973691306571 \n",
            "Epoch: 8 Cost:0.6133055800262701 \n",
            "Epoch: 9 Cost:0.5993622210971268 \n",
            "Epoch: 10 Cost:0.58665507620268 \n",
            "Epoch: 11 Cost:0.5749691468881688 \n",
            "Epoch: 12 Cost:0.5638325170551578 \n",
            "Epoch: 13 Cost:0.5536765270124048 \n",
            "Epoch: 14 Cost:0.5439410291358128 \n",
            "Epoch: 15 Cost:0.5345911317551358 \n",
            "Epoch: 16 Cost:0.525618731315379 \n",
            "Epoch: 17 Cost:0.5171362249367314 \n",
            "Epoch: 18 Cost:0.5088953032184427 \n",
            "Epoch: 19 Cost:0.5009791419429787 \n",
            "Epoch: 20 Cost:0.4932791975787879 \n",
            "Epoch: 21 Cost:0.48605353085189373 \n",
            "Epoch: 22 Cost:0.4788425407616518 \n",
            "Epoch: 23 Cost:0.47191474247435505 \n",
            "Epoch: 24 Cost:0.4652562493572265 \n",
            "Epoch: 25 Cost:0.4587453865755533 \n",
            "Epoch: 26 Cost:0.45251994211139696 \n",
            "Epoch: 27 Cost:0.4463388086846712 \n",
            "Epoch: 28 Cost:0.4402669630351203 \n",
            "Epoch: 29 Cost:0.43455277855045515 \n",
            "Epoch: 30 Cost:0.42894018350832575 \n",
            "Epoch: 31 Cost:0.4234019525150141 \n",
            "Epoch: 32 Cost:0.41785657618775796 \n",
            "Epoch: 33 Cost:0.41271507673498564 \n",
            "Epoch: 34 Cost:0.4075037919995837 \n",
            "Epoch: 35 Cost:0.4025843133977349 \n",
            "Epoch: 36 Cost:0.39762812731219255 \n",
            "Epoch: 37 Cost:0.39288747416973513 \n",
            "Epoch: 38 Cost:0.38812903200752075 \n",
            "Epoch: 39 Cost:0.3835893371839963 \n",
            "Epoch: 40 Cost:0.37909529329349434 \n",
            "Epoch: 41 Cost:0.3747191205114333 \n",
            "Epoch: 42 Cost:0.3705234526332463 \n",
            "Epoch: 43 Cost:0.36629956259565943 \n",
            "Epoch: 44 Cost:0.3623437850858546 \n",
            "Epoch: 45 Cost:0.3582208821255582 \n",
            "Epoch: 46 Cost:0.3542844900323601 \n",
            "Epoch: 47 Cost:0.35052610840517073 \n",
            "Epoch: 48 Cost:0.3467831414510527 \n",
            "Epoch: 49 Cost:0.3430595724395058 \n",
            "Epoch: 50 Cost:0.33950652548579363 \n",
            "Epoch: 51 Cost:0.33599356212042414 \n",
            "Epoch: 52 Cost:0.3324742731358982 \n",
            "Epoch: 53 Cost:0.3291944046000904 \n",
            "Epoch: 54 Cost:0.3258438379022883 \n",
            "Epoch: 55 Cost:0.32244284877602225 \n",
            "Epoch: 56 Cost:0.3193603871495543 \n",
            "Epoch: 57 Cost:0.316251221745233 \n",
            "Epoch: 58 Cost:0.31321936088173175 \n",
            "Epoch: 59 Cost:0.31022898149131933 \n",
            "Epoch: 60 Cost:0.30713198809805015 \n",
            "Epoch: 61 Cost:0.3043334643750271 \n",
            "Epoch: 62 Cost:0.30142496994915036 \n",
            "Epoch: 63 Cost:0.29865091644140773 \n",
            "Epoch: 64 Cost:0.2958488419941482 \n",
            "Epoch: 65 Cost:0.29319014109984687 \n",
            "Epoch: 66 Cost:0.29058862232233357 \n",
            "Epoch: 67 Cost:0.2879626018675332 \n",
            "Epoch: 68 Cost:0.285431258280953 \n",
            "Epoch: 69 Cost:0.2829711609378549 \n",
            "Epoch: 70 Cost:0.28047829181509043 \n",
            "Epoch: 71 Cost:0.27809636293863366 \n",
            "Epoch: 72 Cost:0.2757219186080682 \n",
            "Epoch: 73 Cost:0.27344957381612867 \n",
            "Epoch: 74 Cost:0.2711620384487512 \n",
            "Epoch: 75 Cost:0.2689111364899577 \n",
            "Epoch: 76 Cost:0.2666999483160317 \n",
            "Epoch: 77 Cost:0.26461832894808135 \n",
            "Epoch: 78 Cost:0.26243246856667607 \n",
            "Epoch: 79 Cost:0.2603578870982314 \n",
            "Epoch: 80 Cost:0.25834009778304096 \n",
            "Epoch: 81 Cost:0.25639592304374487 \n",
            "Epoch: 82 Cost:0.2543977059735338 \n",
            "Epoch: 83 Cost:0.25250851775231253 \n",
            "Epoch: 84 Cost:0.25063845460941875 \n",
            "Epoch: 85 Cost:0.24878423005783773 \n",
            "Epoch: 86 Cost:0.24702874533447683 \n",
            "Epoch: 87 Cost:0.2452087710369004 \n",
            "Epoch: 88 Cost:0.24348635315514922 \n",
            "Epoch: 89 Cost:0.24172877191611009 \n",
            "Epoch: 90 Cost:0.24008337694534043 \n",
            "Epoch: 91 Cost:0.23837711131003667 \n",
            "Epoch: 92 Cost:0.2369383762383363 \n",
            "Epoch: 93 Cost:0.23538157836979948 \n",
            "Epoch: 94 Cost:0.2338197412952862 \n",
            "Epoch: 95 Cost:0.23222283232496366 \n",
            "Epoch: 96 Cost:0.23081163275377398 \n",
            "Epoch: 97 Cost:0.22940479301001607 \n",
            "Epoch: 98 Cost:0.22799129184846612 \n",
            "Epoch: 99 Cost:0.22664324908580938 \n",
            "Epoch: 100 Cost:0.2252889392155013 \n",
            "Test accuracy: 96.92% \n"
          ]
        }
      ]
    }
  ]
}